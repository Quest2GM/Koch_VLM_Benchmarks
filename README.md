## Introduction
This repository aims to reproduce the results of recent publications that use vision-language models (VLMs) for robot manipulation tasks on low-cost DIY manipulators. The goal is to create a centralized hub for VLM-based manipulator projects, enabling rapid testing and benchmarking. I chose the [Koch v1.1](https://github.com/jess-moss/koch-v1-1) manipulator to start, due to its compatibility with [lerobot](https://github.com/huggingface/lerobot).

Note: The koch v1-1 is only 5DoF, which may be inconvenient for more complex experiments. I would recommend a 6DoF robot in the future (ex. [Simple Automation](https://docs.google.com/spreadsheets/d/1i-t-i7dLayyafxtfTy8_VctcmbbnCp6Mays1JUR9Qg4/edit?gid=47726668#gid=47726668)).

## The Robot
### DH Table



### Inverse Kinematics